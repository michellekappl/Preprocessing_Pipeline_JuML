# Example corpus for testing
corpus = [
   "I have 5 apples and 10 oranges.",
   "The price is 12.50. Where does the 1/2 â‚¬ come from?",
   "The year is 2024."
]

@testset "Standardize Encoding Tests" begin
   # -----------------------------------------------------
   # Test replacing invalid tokens with <UNK> for ASCII encoding
   # This tests non-ASCII characters like ðŸ˜„, which should be replaced by <UNK>
   # -----------------------------------------------------
   pipe = NlpPipe(["I love programming ðŸ’»", "This is fun! ðŸ˜„"]) |> tokenize |> standardize_encoding
   @test pipe.corpus == ["I love programming ðŸ’»", "This is fun! ðŸ˜„"]  # Corpus should remain the same
   @test pipe.tokens[1] == ["I", "love", "programming", "<UNK>"]  # ðŸ’» is replaced with <UNK>
   @test pipe.tokens[2] == ["This", "is", "fun!", "<UNK>"]  # ðŸ˜„ is replaced with <UNK>

   # -----------------------------------------------------
   # Test with UTF-8 encoding for the same corpus
   # UTF-8 encoding should retain all special characters like ðŸ’» and ðŸ˜„
   # -----------------------------------------------------
   pipe = NlpPipe(["I love programming ðŸ’»", "This is fun! ðŸ˜„"]) |> tokenize |> pipe -> standardize_encoding(pipe, encoding="UTF-8")
   @test pipe.corpus == ["I love programming ðŸ’»", "This is fun! ðŸ˜„"]
   @test pipe.tokens[1] == ["I", "love", "programming", "ðŸ’»"]
   @test pipe.tokens[2] == ["This", "is", "fun!", "ðŸ˜„"]
end
